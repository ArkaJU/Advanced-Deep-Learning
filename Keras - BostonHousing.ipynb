{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing = keras.datasets.boston_housing\n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "order = np.argsort(np.random.random(train_labels.shape))\n",
    "train_data = train_data[order]\n",
    "train_labels = train_labels[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (404, 13)\n",
      "Test set: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: {}\".format(train_data.shape))\n",
    "print(\"Test set: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.127</td>\n",
       "      <td>18.4</td>\n",
       "      <td>5.5027</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76162</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>5.560</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.9865</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>392.40</td>\n",
       "      <td>10.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>6.382</td>\n",
       "      <td>67.2</td>\n",
       "      <td>3.5325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>395.21</td>\n",
       "      <td>10.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.22358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.943</td>\n",
       "      <td>97.4</td>\n",
       "      <td>1.8773</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>363.43</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.232</td>\n",
       "      <td>53.7</td>\n",
       "      <td>5.0141</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>386.40</td>\n",
       "      <td>12.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.08265   0.0  13.92   0.0  0.437  6.127  18.4  5.5027  4.0  289.0   \n",
       "1  0.76162  20.0   3.97   0.0  0.647  5.560  62.8  1.9865  5.0  264.0   \n",
       "2  0.40202   0.0   9.90   0.0  0.544  6.382  67.2  3.5325  4.0  304.0   \n",
       "3  1.22358   0.0  19.58   0.0  0.605  6.943  97.4  1.8773  5.0  403.0   \n",
       "4  0.05646   0.0  12.83   0.0  0.437  6.232  53.7  5.0141  5.0  398.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     16.0  396.90   8.58  \n",
       "1     13.0  392.40  10.45  \n",
       "2     18.4  395.21  10.36  \n",
       "3     14.7  363.43   4.59  \n",
       "4     18.7  386.40  12.34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "                'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "df = pd.DataFrame(train_data, columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data = (train_data-mean)/std\n",
    "test_data = (test_data-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 521.6662 - mean_absolute_error: 21.1305 - val_loss: 484.2761 - val_mean_absolute_error: 19.4732\n",
      "Epoch 2/200\n",
      " - 0s - loss: 337.6388 - mean_absolute_error: 16.6145 - val_loss: 236.2128 - val_mean_absolute_error: 12.3155\n",
      "Epoch 3/200\n",
      " - 0s - loss: 117.7850 - mean_absolute_error: 8.8751 - val_loss: 103.6770 - val_mean_absolute_error: 7.1865\n",
      "Epoch 4/200\n",
      " - 0s - loss: 48.9131 - mean_absolute_error: 5.3054 - val_loss: 70.4328 - val_mean_absolute_error: 5.6361\n",
      "Epoch 5/200\n",
      " - 0s - loss: 30.8684 - mean_absolute_error: 4.0779 - val_loss: 51.4119 - val_mean_absolute_error: 4.5901\n",
      "Epoch 6/200\n",
      " - 0s - loss: 24.6904 - mean_absolute_error: 3.6473 - val_loss: 43.8071 - val_mean_absolute_error: 4.1805\n",
      "Epoch 7/200\n",
      " - 0s - loss: 21.5117 - mean_absolute_error: 3.3955 - val_loss: 39.2102 - val_mean_absolute_error: 3.8687\n",
      "Epoch 8/200\n",
      " - 0s - loss: 19.3025 - mean_absolute_error: 3.1793 - val_loss: 36.1233 - val_mean_absolute_error: 3.7430\n",
      "Epoch 9/200\n",
      " - 0s - loss: 17.8095 - mean_absolute_error: 3.0478 - val_loss: 33.9485 - val_mean_absolute_error: 3.6213\n",
      "Epoch 10/200\n",
      " - 0s - loss: 16.4791 - mean_absolute_error: 2.9021 - val_loss: 32.6357 - val_mean_absolute_error: 3.5666\n",
      "Epoch 11/200\n",
      " - 0s - loss: 15.5352 - mean_absolute_error: 2.8134 - val_loss: 31.2829 - val_mean_absolute_error: 3.3763\n",
      "Epoch 12/200\n",
      " - 0s - loss: 14.6554 - mean_absolute_error: 2.7211 - val_loss: 29.8024 - val_mean_absolute_error: 3.3498\n",
      "Epoch 13/200\n",
      " - 0s - loss: 13.7437 - mean_absolute_error: 2.6367 - val_loss: 28.2760 - val_mean_absolute_error: 3.2438\n",
      "Epoch 14/200\n",
      " - 0s - loss: 13.1403 - mean_absolute_error: 2.5192 - val_loss: 27.2948 - val_mean_absolute_error: 3.1985\n",
      "Epoch 15/200\n",
      " - 0s - loss: 12.5897 - mean_absolute_error: 2.4939 - val_loss: 26.2658 - val_mean_absolute_error: 3.1776\n",
      "Epoch 16/200\n",
      " - 0s - loss: 11.9671 - mean_absolute_error: 2.4263 - val_loss: 25.5032 - val_mean_absolute_error: 3.0773\n",
      "Epoch 17/200\n",
      " - 0s - loss: 11.5078 - mean_absolute_error: 2.3855 - val_loss: 24.5175 - val_mean_absolute_error: 3.0389\n",
      "Epoch 18/200\n",
      " - 0s - loss: 11.2175 - mean_absolute_error: 2.3360 - val_loss: 24.3525 - val_mean_absolute_error: 3.0035\n",
      "Epoch 19/200\n",
      " - 0s - loss: 11.1072 - mean_absolute_error: 2.3799 - val_loss: 23.2640 - val_mean_absolute_error: 2.9230\n",
      "Epoch 20/200\n",
      " - 0s - loss: 10.9987 - mean_absolute_error: 2.2715 - val_loss: 22.3830 - val_mean_absolute_error: 3.1022\n",
      "Epoch 21/200\n",
      " - 0s - loss: 10.2828 - mean_absolute_error: 2.2836 - val_loss: 22.0274 - val_mean_absolute_error: 2.8991\n",
      "Epoch 22/200\n",
      " - 0s - loss: 10.2212 - mean_absolute_error: 2.2518 - val_loss: 21.3467 - val_mean_absolute_error: 2.8827\n",
      "Epoch 23/200\n",
      " - 0s - loss: 9.8512 - mean_absolute_error: 2.1851 - val_loss: 20.9793 - val_mean_absolute_error: 2.8661\n",
      "Epoch 24/200\n",
      " - 0s - loss: 9.7714 - mean_absolute_error: 2.1922 - val_loss: 20.6438 - val_mean_absolute_error: 2.9148\n",
      "Epoch 25/200\n",
      " - 0s - loss: 9.3999 - mean_absolute_error: 2.1680 - val_loss: 19.9641 - val_mean_absolute_error: 2.8212\n",
      "Epoch 26/200\n",
      " - 0s - loss: 9.3063 - mean_absolute_error: 2.1576 - val_loss: 19.5251 - val_mean_absolute_error: 2.8401\n",
      "Epoch 27/200\n",
      " - 0s - loss: 9.1165 - mean_absolute_error: 2.1327 - val_loss: 19.3661 - val_mean_absolute_error: 2.7941\n",
      "Epoch 28/200\n",
      " - 0s - loss: 9.0728 - mean_absolute_error: 2.1479 - val_loss: 19.2580 - val_mean_absolute_error: 2.8198\n",
      "Epoch 29/200\n",
      " - 0s - loss: 8.8843 - mean_absolute_error: 2.1041 - val_loss: 18.8524 - val_mean_absolute_error: 2.8114\n",
      "Epoch 30/200\n",
      " - 0s - loss: 8.7872 - mean_absolute_error: 2.1148 - val_loss: 18.3708 - val_mean_absolute_error: 2.7166\n",
      "Epoch 31/200\n",
      " - 0s - loss: 8.5171 - mean_absolute_error: 2.0788 - val_loss: 17.5749 - val_mean_absolute_error: 2.7359\n",
      "Epoch 32/200\n",
      " - 0s - loss: 8.4085 - mean_absolute_error: 2.0841 - val_loss: 17.9237 - val_mean_absolute_error: 2.6011\n",
      "Epoch 33/200\n",
      " - 0s - loss: 8.4503 - mean_absolute_error: 2.0697 - val_loss: 17.2351 - val_mean_absolute_error: 2.7240\n",
      "Epoch 34/200\n",
      " - 0s - loss: 8.1815 - mean_absolute_error: 2.0484 - val_loss: 17.0740 - val_mean_absolute_error: 2.6502\n",
      "Epoch 35/200\n",
      " - 0s - loss: 8.1356 - mean_absolute_error: 2.0270 - val_loss: 17.0598 - val_mean_absolute_error: 2.7260\n",
      "Epoch 36/200\n",
      " - 0s - loss: 8.0631 - mean_absolute_error: 2.0434 - val_loss: 17.7035 - val_mean_absolute_error: 2.6556\n",
      "Epoch 37/200\n",
      " - 0s - loss: 8.0959 - mean_absolute_error: 2.0580 - val_loss: 16.4777 - val_mean_absolute_error: 2.6238\n",
      "Epoch 38/200\n",
      " - 0s - loss: 7.9046 - mean_absolute_error: 2.0423 - val_loss: 16.1169 - val_mean_absolute_error: 2.6292\n",
      "Epoch 39/200\n",
      " - 0s - loss: 7.7322 - mean_absolute_error: 2.0018 - val_loss: 16.0083 - val_mean_absolute_error: 2.5765\n",
      "Epoch 40/200\n",
      " - 0s - loss: 7.8701 - mean_absolute_error: 2.0686 - val_loss: 15.1034 - val_mean_absolute_error: 2.5086\n",
      "Epoch 41/200\n",
      " - 0s - loss: 7.6233 - mean_absolute_error: 2.0331 - val_loss: 15.2549 - val_mean_absolute_error: 2.5202\n",
      "Epoch 42/200\n",
      " - 0s - loss: 7.3851 - mean_absolute_error: 1.9681 - val_loss: 14.9449 - val_mean_absolute_error: 2.5111\n",
      "Epoch 43/200\n",
      " - 0s - loss: 7.4123 - mean_absolute_error: 1.9596 - val_loss: 15.3023 - val_mean_absolute_error: 2.6137\n",
      "Epoch 44/200\n",
      " - 0s - loss: 7.1699 - mean_absolute_error: 1.9583 - val_loss: 15.4913 - val_mean_absolute_error: 2.5053\n",
      "Epoch 45/200\n",
      " - 0s - loss: 7.2661 - mean_absolute_error: 1.9497 - val_loss: 15.1945 - val_mean_absolute_error: 2.6894\n",
      "Epoch 46/200\n",
      " - 0s - loss: 7.2448 - mean_absolute_error: 1.9695 - val_loss: 14.5753 - val_mean_absolute_error: 2.4746\n",
      "Epoch 47/200\n",
      " - 0s - loss: 6.9602 - mean_absolute_error: 1.9156 - val_loss: 14.7688 - val_mean_absolute_error: 2.4441\n",
      "Epoch 48/200\n",
      " - 0s - loss: 7.1587 - mean_absolute_error: 1.9316 - val_loss: 14.7307 - val_mean_absolute_error: 2.5444\n",
      "Epoch 49/200\n",
      " - 0s - loss: 6.8984 - mean_absolute_error: 1.8982 - val_loss: 14.7776 - val_mean_absolute_error: 2.4670\n",
      "Epoch 50/200\n",
      " - 0s - loss: 7.1251 - mean_absolute_error: 1.9077 - val_loss: 15.4904 - val_mean_absolute_error: 2.6969\n",
      "Epoch 51/200\n",
      " - 0s - loss: 7.0762 - mean_absolute_error: 1.9400 - val_loss: 14.3452 - val_mean_absolute_error: 2.4774\n",
      "Epoch 52/200\n",
      " - 0s - loss: 6.6331 - mean_absolute_error: 1.8723 - val_loss: 13.9511 - val_mean_absolute_error: 2.3585\n",
      "Epoch 53/200\n",
      " - 0s - loss: 6.5598 - mean_absolute_error: 1.8788 - val_loss: 14.1547 - val_mean_absolute_error: 2.5325\n",
      "Epoch 54/200\n",
      " - 0s - loss: 6.5952 - mean_absolute_error: 1.8701 - val_loss: 13.8030 - val_mean_absolute_error: 2.4098\n",
      "Epoch 55/200\n",
      " - 0s - loss: 6.4644 - mean_absolute_error: 1.8257 - val_loss: 14.3967 - val_mean_absolute_error: 2.5851\n",
      "Epoch 56/200\n",
      " - 0s - loss: 6.5536 - mean_absolute_error: 1.8955 - val_loss: 13.4379 - val_mean_absolute_error: 2.3685\n",
      "Epoch 57/200\n",
      " - 0s - loss: 6.2185 - mean_absolute_error: 1.8277 - val_loss: 13.9054 - val_mean_absolute_error: 2.2900\n",
      "Epoch 58/200\n",
      " - 0s - loss: 6.3496 - mean_absolute_error: 1.8442 - val_loss: 14.5731 - val_mean_absolute_error: 2.6085\n",
      "Epoch 59/200\n",
      " - 0s - loss: 6.0690 - mean_absolute_error: 1.8168 - val_loss: 13.4314 - val_mean_absolute_error: 2.3581\n",
      "Epoch 60/200\n",
      " - 0s - loss: 6.2998 - mean_absolute_error: 1.8391 - val_loss: 13.5220 - val_mean_absolute_error: 2.3841\n",
      "Epoch 61/200\n",
      " - 0s - loss: 6.2112 - mean_absolute_error: 1.8377 - val_loss: 13.8088 - val_mean_absolute_error: 2.5076\n",
      "Epoch 62/200\n",
      " - 0s - loss: 6.0107 - mean_absolute_error: 1.7992 - val_loss: 12.9829 - val_mean_absolute_error: 2.2982\n",
      "Epoch 63/200\n",
      " - 0s - loss: 6.0239 - mean_absolute_error: 1.7868 - val_loss: 13.4802 - val_mean_absolute_error: 2.4323\n",
      "Epoch 64/200\n",
      " - 0s - loss: 5.8992 - mean_absolute_error: 1.7923 - val_loss: 13.1149 - val_mean_absolute_error: 2.3651\n",
      "Epoch 65/200\n",
      " - 0s - loss: 5.8207 - mean_absolute_error: 1.7667 - val_loss: 13.3434 - val_mean_absolute_error: 2.3898\n",
      "Epoch 66/200\n",
      " - 0s - loss: 6.4089 - mean_absolute_error: 1.8966 - val_loss: 12.3220 - val_mean_absolute_error: 2.2404\n",
      "Epoch 67/200\n",
      " - 0s - loss: 5.5401 - mean_absolute_error: 1.7228 - val_loss: 13.2395 - val_mean_absolute_error: 2.4154\n",
      "Epoch 68/200\n",
      " - 0s - loss: 5.5772 - mean_absolute_error: 1.7519 - val_loss: 12.8406 - val_mean_absolute_error: 2.2797\n",
      "Epoch 69/200\n",
      " - 0s - loss: 5.5143 - mean_absolute_error: 1.7347 - val_loss: 12.5865 - val_mean_absolute_error: 2.2301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      " - 0s - loss: 5.6524 - mean_absolute_error: 1.7465 - val_loss: 13.2324 - val_mean_absolute_error: 2.4618\n",
      "Epoch 71/200\n",
      " - 0s - loss: 5.4776 - mean_absolute_error: 1.7132 - val_loss: 12.8915 - val_mean_absolute_error: 2.3810\n",
      "Epoch 72/200\n",
      " - 0s - loss: 5.3331 - mean_absolute_error: 1.7128 - val_loss: 12.6144 - val_mean_absolute_error: 2.2972\n",
      "Epoch 73/200\n",
      " - 0s - loss: 5.0765 - mean_absolute_error: 1.6580 - val_loss: 12.7474 - val_mean_absolute_error: 2.2908\n",
      "Epoch 74/200\n",
      " - 0s - loss: 5.3519 - mean_absolute_error: 1.7203 - val_loss: 12.9142 - val_mean_absolute_error: 2.3277\n",
      "Epoch 75/200\n",
      " - 0s - loss: 5.3020 - mean_absolute_error: 1.7076 - val_loss: 12.5368 - val_mean_absolute_error: 2.2061\n",
      "Epoch 76/200\n",
      " - 0s - loss: 5.2543 - mean_absolute_error: 1.6688 - val_loss: 12.6049 - val_mean_absolute_error: 2.1692\n",
      "Epoch 77/200\n",
      " - 0s - loss: 5.4228 - mean_absolute_error: 1.7102 - val_loss: 12.8715 - val_mean_absolute_error: 2.3014\n",
      "Epoch 78/200\n",
      " - 0s - loss: 5.0600 - mean_absolute_error: 1.6535 - val_loss: 12.3664 - val_mean_absolute_error: 2.2273\n",
      "Epoch 79/200\n",
      " - 0s - loss: 4.9813 - mean_absolute_error: 1.6620 - val_loss: 12.4674 - val_mean_absolute_error: 2.2507\n",
      "Epoch 80/200\n",
      " - 0s - loss: 4.8566 - mean_absolute_error: 1.6403 - val_loss: 12.3808 - val_mean_absolute_error: 2.2368\n",
      "Epoch 81/200\n",
      " - 0s - loss: 4.7669 - mean_absolute_error: 1.5947 - val_loss: 12.8168 - val_mean_absolute_error: 2.3014\n",
      "Epoch 82/200\n",
      " - 0s - loss: 4.9144 - mean_absolute_error: 1.6420 - val_loss: 12.6926 - val_mean_absolute_error: 2.3631\n",
      "Epoch 83/200\n",
      " - 0s - loss: 4.8586 - mean_absolute_error: 1.6404 - val_loss: 12.1486 - val_mean_absolute_error: 2.1702\n",
      "Epoch 84/200\n",
      " - 0s - loss: 4.9551 - mean_absolute_error: 1.6282 - val_loss: 12.6918 - val_mean_absolute_error: 2.2081\n",
      "Epoch 85/200\n",
      " - 0s - loss: 4.5840 - mean_absolute_error: 1.5678 - val_loss: 12.1196 - val_mean_absolute_error: 2.2434\n",
      "Epoch 86/200\n",
      " - 0s - loss: 4.4173 - mean_absolute_error: 1.5622 - val_loss: 12.1055 - val_mean_absolute_error: 2.2451\n",
      "Epoch 87/200\n",
      " - 0s - loss: 4.3663 - mean_absolute_error: 1.5489 - val_loss: 12.0993 - val_mean_absolute_error: 2.2354\n",
      "Epoch 88/200\n",
      " - 0s - loss: 4.3373 - mean_absolute_error: 1.5372 - val_loss: 12.0434 - val_mean_absolute_error: 2.1693\n",
      "Epoch 89/200\n",
      " - 0s - loss: 4.1990 - mean_absolute_error: 1.5184 - val_loss: 12.9893 - val_mean_absolute_error: 2.4974\n",
      "Epoch 90/200\n",
      " - 0s - loss: 4.4579 - mean_absolute_error: 1.5747 - val_loss: 12.3748 - val_mean_absolute_error: 2.3454\n",
      "Epoch 91/200\n",
      " - 0s - loss: 4.1139 - mean_absolute_error: 1.4774 - val_loss: 13.3825 - val_mean_absolute_error: 2.4819\n",
      "Epoch 92/200\n",
      " - 0s - loss: 4.0838 - mean_absolute_error: 1.5118 - val_loss: 12.1648 - val_mean_absolute_error: 2.2804\n",
      "Epoch 93/200\n",
      " - 0s - loss: 4.0923 - mean_absolute_error: 1.4961 - val_loss: 12.3697 - val_mean_absolute_error: 2.3218\n",
      "Epoch 94/200\n",
      " - 0s - loss: 4.0072 - mean_absolute_error: 1.4704 - val_loss: 12.2009 - val_mean_absolute_error: 2.2591\n",
      "Epoch 95/200\n",
      " - 0s - loss: 3.9131 - mean_absolute_error: 1.4774 - val_loss: 12.1305 - val_mean_absolute_error: 2.2749\n",
      "Epoch 96/200\n",
      " - 0s - loss: 3.8926 - mean_absolute_error: 1.4698 - val_loss: 12.5149 - val_mean_absolute_error: 2.3640\n",
      "Epoch 97/200\n",
      " - 0s - loss: 3.8596 - mean_absolute_error: 1.4320 - val_loss: 12.9294 - val_mean_absolute_error: 2.4728\n",
      "Epoch 98/200\n",
      " - 0s - loss: 4.0704 - mean_absolute_error: 1.4949 - val_loss: 13.5844 - val_mean_absolute_error: 2.5682\n",
      "Epoch 99/200\n",
      " - 0s - loss: 3.9854 - mean_absolute_error: 1.4879 - val_loss: 12.8888 - val_mean_absolute_error: 2.4584\n",
      "Epoch 100/200\n",
      " - 0s - loss: 4.0149 - mean_absolute_error: 1.4664 - val_loss: 12.8209 - val_mean_absolute_error: 2.4821\n",
      "Epoch 101/200\n",
      " - 0s - loss: 3.6876 - mean_absolute_error: 1.3882 - val_loss: 12.7624 - val_mean_absolute_error: 2.4418\n",
      "Epoch 102/200\n",
      " - 0s - loss: 3.7270 - mean_absolute_error: 1.4154 - val_loss: 13.0072 - val_mean_absolute_error: 2.5171\n",
      "Epoch 103/200\n",
      " - 0s - loss: 3.5456 - mean_absolute_error: 1.3892 - val_loss: 12.9735 - val_mean_absolute_error: 2.4863\n",
      "Epoch 104/200\n",
      " - 0s - loss: 3.5128 - mean_absolute_error: 1.3591 - val_loss: 12.5078 - val_mean_absolute_error: 2.3867\n",
      "Epoch 105/200\n",
      " - 0s - loss: 3.5598 - mean_absolute_error: 1.4175 - val_loss: 13.2217 - val_mean_absolute_error: 2.4924\n",
      "Epoch 106/200\n",
      " - 0s - loss: 3.6661 - mean_absolute_error: 1.4154 - val_loss: 12.5083 - val_mean_absolute_error: 2.3919\n",
      "Epoch 107/200\n",
      " - 0s - loss: 3.6561 - mean_absolute_error: 1.3899 - val_loss: 13.3643 - val_mean_absolute_error: 2.5196\n",
      "Epoch 108/200\n",
      " - 0s - loss: 3.4165 - mean_absolute_error: 1.4065 - val_loss: 13.3800 - val_mean_absolute_error: 2.5384\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(train_data.shape[1],)))\n",
    "model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1))\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "history = model.fit(train_data, train_labels, batch_size=10, epochs=200, validation_split=0.2, verbose=2, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Abs Error [1000$]')\n",
    "plt.plot(history.epoch, np.array(history.history['mean_absolute_error']), \n",
    "           label='Train Loss')\n",
    "plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "plt.legend()\n",
    "plt.ylim([0,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: $2432.69\n"
     ]
    }
   ],
   "source": [
    "[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
